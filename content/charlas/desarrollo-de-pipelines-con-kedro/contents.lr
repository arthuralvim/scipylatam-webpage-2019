authors: cristian-contreras
---
description: El desarrollo de soluciones de Analytics y Machine Learning puede dividirse en 4 grandes fases: obtención de datos a partir de fuentes; preprocesamiento de datos; creación de modelos y validación; y creación de componentes derivados como reportes y APIs. Conceptualmente, estas fases forman un pipeline de procesamiento desde datos raw hasta resultados. En proyectos pequeños y medianos es simple organizar desarrollar todo el producto a través de scripts y funciones, muchas veces todo en un solo notebook de Jupyter. No obstante, este tipo de soluciones sufren de problemas de escalabilidad a medida que la complejidad del problema a resolver (y código) incrementa. Además de ello, estas soluciones generan dificultades a la hora de trabajar en equipo, pues cada integrante del equipo puede tener su forma particular de organizar su código y proyectos. A esto se suma que el código complejo se hace difícil de validar, particularmente si no se encuentra modularizado.   Para solventar estas dificultades, podemos usar un framework, que, basado en las mejores prácticas en la industria, estandariza las metodologías de procesamiento de datos para el equipo y organiza los pipelines en sub-módulos y dependencias aislados. Uno de estos frameworks es kedro, una librería desarrollada para Python por QuantumBlack. En kedro, organizamos pipelines en módulos atómicos de preprocesamiento a través de funciones puras de Python que dependen entre sí por medio de datos. Kedro ejecuta automáticamente el código en el orden apropiado, especificado por las dependencias, y se encarga del cargue de datos para permitir enfocarnos solamente en los detalles del código de procesamiento y de entrenamiento de modelos. Lo mejor de todo, es que podemos complementar el desarrollo a través de prototipado en Jupyter. En este taller veremos un ejemplo básico de pipelines en el contexto del desarrollo de un modelo de Machine Learning.   
---
language: es
---
language_slides: es
---
level: intermediate
---
name: Desarrollo de pipelines con Kedro
---
summary: Con la complejidad incremental de análisis de datos, es necesario estructurar nuestro código en pipelines con el fin de mantener legibilidad, facilitar desarrollo iterativo de modelos y simplificar colaboración en equipos. Trabajaremos en desarrollar dichos pipelines con la librería Kedro.
---
type: workshop
